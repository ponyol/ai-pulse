<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Anthropic Повний Фід - AI-PULSE</title>
    <link>https://www.anthropic.com</link>
    <description>Повний фід: новини, інженерія та дослідження безпеки ШІ від Anthropic (українською мовою)</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>AI-PULSE RSS Generator - Ukrainian Complete Translation</generator>
    <language>uk</language>
    <lastBuildDate>Wed, 19 Nov 2025 08:30:57 +0000</lastBuildDate>
    <item>
      <title>[Безпека ШІ] Reasoning Models Don't Always Say What They Think</title>
      <link>https://www.anthropic.com/research/reasoning-models-dont-say-think</link>
      <description>AI Safety research: We find that reasoning models don't always accurately verbalize their reasoning. This casts doubt on
                   ... (Джерело: Alignment Science)</description>
      <guid isPermaLink="false">https://www.anthropic.com/research/reasoning-models-dont-say-think</guid>
      <category>Alignment Science</category>
      <pubDate>Wed, 19 Nov 2025 08:30:57 +0000</pubDate>
    </item>
    <item>
      <title>[Безпека ШІ] Alignment Faking Revisited: Improved Classifiers and Open Source Extensions</title>
      <link>https://alignment.anthropic.com/2025/alignment-faking-revisited/</link>
      <description>AI Safety research: We present a replication and extension of an alignment faking model organism.... (Джерело: Alignment Science)</description>
      <guid isPermaLink="false">https://alignment.anthropic.com/2025/alignment-faking-revisited/</guid>
      <category>Alignment Science</category>
      <pubDate>Wed, 19 Nov 2025 08:30:57 +0000</pubDate>
    </item>
    <item>
      <title>[Безпека ШІ] Auditing Language Models for Hidden Objectives</title>
      <link>https://www.anthropic.com/research/auditing-hidden-objectives</link>
      <description>AI Safety research: We deliberately train a language model with a hidden objective and use it as a testbed for studying
                    ... (Джерело: Alignment Science)</description>
      <guid isPermaLink="false">https://www.anthropic.com/research/auditing-hidden-objectives</guid>
      <category>Alignment Science</category>
      <pubDate>Wed, 19 Nov 2025 08:30:57 +0000</pubDate>
    </item>
    <item>
      <title>[Безпека ШІ] Automated Researchers Can Subtly Sandbag</title>
      <link>https://alignment.anthropic.com/2025/automated-researchers-sandbag/</link>
      <description>AI Safety research: Current models can sandbag ML experiments and research decisions without being detected by zero-shot
                   ... (Джерело: Alignment Science)</description>
      <guid isPermaLink="false">https://alignment.anthropic.com/2025/automated-researchers-sandbag/</guid>
      <category>Alignment Science</category>
      <pubDate>Wed, 19 Nov 2025 08:30:57 +0000</pubDate>
    </item>
    <item>
      <title>[Безпека ШІ] Introducing Anthropic's Safeguards Research Team</title>
      <link>https://alignment.anthropic.com/2025/introducing-safeguards-research-team/index.html</link>
      <description>AI Safety research: We're launching a new research team focused on mitigating the post-deployment risks of AI systems.... (Джерело: Alignment Science)</description>
      <guid isPermaLink="false">https://alignment.anthropic.com/2025/introducing-safeguards-research-team/index.html</guid>
      <category>Alignment Science</category>
      <pubDate>Wed, 19 Nov 2025 08:30:57 +0000</pubDate>
    </item>
    <item>
      <title>[Безпека ШІ] Forecasting Rare Language Model Behaviors</title>
      <link>https://www.anthropic.com/research/forecasting-rare-behaviors</link>
      <description>AI Safety research: We forecast whether risks will occur after a model is deployed — using even very limited sets of
                    tes... (Джерело: Alignment Science)</description>
      <guid isPermaLink="false">https://www.anthropic.com/research/forecasting-rare-behaviors</guid>
      <category>Alignment Science</category>
      <pubDate>Wed, 19 Nov 2025 08:30:57 +0000</pubDate>
    </item>
    <item>
      <title>[Безпека ШІ] Alignment Faking in Large Language Models</title>
      <link>https://www.anthropic.com/research/alignment-faking</link>
      <description>AI Safety research: We present experiments where Claude often pretends to
                    have different views during training, while ac... (Джерело: Alignment Science)</description>
      <guid isPermaLink="false">https://www.anthropic.com/research/alignment-faking</guid>
      <category>Alignment Science</category>
      <pubDate>Wed, 19 Nov 2025 08:30:57 +0000</pubDate>
    </item>
    <item>
      <title>[Безпека ШІ] How to Replicate and Extend our Alignment Faking Demo</title>
      <link>https://alignment.anthropic.com/2024/how-to-alignment-faking/index.html</link>
      <description>AI Safety research: We describe how to get started with experimenting with
                    our demonstration of alignment faking, and pr... (Джерело: Alignment Science)</description>
      <guid isPermaLink="false">https://alignment.anthropic.com/2024/how-to-alignment-faking/index.html</guid>
      <category>Alignment Science</category>
      <pubDate>Wed, 19 Nov 2025 08:30:57 +0000</pubDate>
    </item>
    <item>
      <title>[Безпека ШІ] Sabotage Evaluations for Frontier Models</title>
      <link>https://www.anthropic.com/research/sabotage-evaluations</link>
      <description>AI Safety research: How well could AI models mislead us, or secretly
                    sabotage tasks, if they were trying to? We describe... (Джерело: Alignment Science)</description>
      <guid isPermaLink="false">https://www.anthropic.com/research/sabotage-evaluations</guid>
      <category>Alignment Science</category>
      <pubDate>Wed, 19 Nov 2025 08:30:57 +0000</pubDate>
    </item>
    <item>
      <title>[Безпека ШІ] Simple Probes can Catch Sleeper Agents</title>
      <link>https://www.anthropic.com/research/probes-catch-sleeper-agents</link>
      <description>AI Safety research: We find that probing, a simple interpretability
                    technique, can detect when backdoored "sleeper agent... (Джерело: Alignment Science)</description>
      <guid isPermaLink="false">https://www.anthropic.com/research/probes-catch-sleeper-agents</guid>
      <category>Alignment Science</category>
      <pubDate>Wed, 19 Nov 2025 08:30:57 +0000</pubDate>
    </item>
    <item>
      <title>[Безпека ШІ] Sleeper Agents: Training Deceptive LLMs that Persist
                    Through Safety Training</title>
      <link>https://www.anthropic.com/research/sleeper-agents-training-deceptive-llms-that-persist-through-safety-training</link>
      <description>AI Safety research: We train LLMs to act secretly malicious. We find that,
                    despite our best efforts at alignment trainin... (Джерело: Alignment Science)</description>
      <guid isPermaLink="false">https://www.anthropic.com/research/sleeper-agents-training-deceptive-llms-that-persist-through-safety-training</guid>
      <category>Alignment Science</category>
      <pubDate>Wed, 19 Nov 2025 08:30:57 +0000</pubDate>
    </item>
    <item>
      <title>[Безпека ШІ] Discovering Language Model Behaviors with Model-Written
                    Evaluations</title>
      <link>https://www.anthropic.com/research/discovering-language-model-behaviors-with-model-written-evaluations</link>
      <description>AI Safety research: We develop an automated way to generate language model
                    (LM) evaluations with LMs, significantly redu... (Джерело: Alignment Science)</description>
      <guid isPermaLink="false">https://www.anthropic.com/research/discovering-language-model-behaviors-with-model-written-evaluations</guid>
      <category>Alignment Science</category>
      <pubDate>Wed, 19 Nov 2025 08:30:57 +0000</pubDate>
    </item>
    <item>
      <title>[Безпека ШІ] Alignment Science Blog</title>
      <link>https://alignment.anthropic.com/2025/strengthening-red-teams/</link>
      <description>AI Safety research: We decompose sabotage into constituent skills and use synthetic simulations to strengthen attacks in
                   ... (Джерело: Alignment Science)</description>
      <guid isPermaLink="false">https://alignment.anthropic.com/2025/strengthening-red-teams/</guid>
      <category>Alignment Science</category>
      <pubDate>Wed, 19 Nov 2025 08:30:57 +0000</pubDate>
    </item>
    <item>
      <title>[Інженерія] Effective context engineering for AI agents</title>
      <link>https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents</link>
      <description>Engineering insights: Effective context engineering for AI agentsSep 29, 2025... (Джерело: Engineering)</description>
      <guid isPermaLink="false">https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents</guid>
      <category>Engineering</category>
      <pubDate>Wed, 19 Nov 2025 08:30:57 +0000</pubDate>
    </item>
    <item>
      <title>[Інженерія] Desktop Extensions: One-click MCP server installation for Claude Desktop</title>
      <link>https://www.anthropic.com/engineering/desktop-extensions</link>
      <description>Engineering insights: Desktop Extensions: One-click MCP server installation for Claude DesktopJun 26, 2025... (Джерело: Engineering)</description>
      <guid isPermaLink="false">https://www.anthropic.com/engineering/desktop-extensions</guid>
      <category>Engineering</category>
      <pubDate>Wed, 19 Nov 2025 08:30:57 +0000</pubDate>
    </item>
    <item>
      <title>[Інженерія] How we built our multi-agent research system</title>
      <link>https://www.anthropic.com/engineering/multi-agent-research-system</link>
      <description>Engineering insights: How we built our multi-agent research systemJun 13, 2025... (Джерело: Engineering)</description>
      <guid isPermaLink="false">https://www.anthropic.com/engineering/multi-agent-research-system</guid>
      <category>Engineering</category>
      <pubDate>Wed, 19 Nov 2025 08:30:57 +0000</pubDate>
    </item>
    <item>
      <title>[Інженерія] Claude Code: Best practices for agentic coding</title>
      <link>https://www.anthropic.com/engineering/claude-code-best-practices</link>
      <description>Engineering insights: Claude Code: Best practices for agentic codingApr 18, 2025... (Джерело: Engineering)</description>
      <guid isPermaLink="false">https://www.anthropic.com/engineering/claude-code-best-practices</guid>
      <category>Engineering</category>
      <pubDate>Wed, 19 Nov 2025 08:30:57 +0000</pubDate>
    </item>
    <item>
      <title>[Інженерія] Engineering at Anthropic: Inside the team building reliable AI systems</title>
      <link>https://console.anthropic.com/</link>
      <description>Engineering insights from Anthropic: Engineering at Anthropic: Inside the team building reliable AI systems (Джерело: Engineering)</description>
      <guid isPermaLink="false">https://console.anthropic.com/</guid>
      <category>Engineering</category>
      <pubDate>Wed, 19 Nov 2025 08:30:57 +0000</pubDate>
    </item>
    <item>
      <title>[Новини] Introducing Claude Sonnet 4.5</title>
      <link>https://www.anthropic.com/news/claude-sonnet-4-5</link>
      <description>Latest from Anthropic: Introducing Claude Sonnet 4.5 (Джерело: News)</description>
      <guid isPermaLink="false">https://www.anthropic.com/news/claude-sonnet-4-5</guid>
      <category>Policy</category>
      <pubDate>Wed, 19 Nov 2025 08:30:57 +0000</pubDate>
    </item>
    <item>
      <title>[Новини] Thoughts on America’s AI Action Plan</title>
      <link>https://www.anthropic.com/news/thoughts-on-america-s-ai-action-plan</link>
      <description>Latest from Anthropic: Thoughts on America’s AI Action Plan (Джерело: News)</description>
      <guid isPermaLink="false">https://www.anthropic.com/news/thoughts-on-america-s-ai-action-plan</guid>
      <category>Policy</category>
      <pubDate>Wed, 19 Nov 2025 08:30:57 +0000</pubDate>
    </item>
    <item>
      <title>[Новини] Anthropic raises $13B Series F at $183B post-money valuation</title>
      <link>https://www.anthropic.com/news/anthropic-raises-series-f-at-usd183b-post-money-valuation</link>
      <description>Latest from Anthropic: Anthropic raises $13B Series F at $183B post-money valuation (Джерело: News)</description>
      <guid isPermaLink="false">https://www.anthropic.com/news/anthropic-raises-series-f-at-usd183b-post-money-valuation</guid>
      <category>Announcements</category>
      <pubDate>Wed, 19 Nov 2025 08:30:57 +0000</pubDate>
    </item>
    <item>
      <title>[Новини] Anthropic Economic Index report: Uneven geographic and enterprise AI adoption</title>
      <link>https://www.anthropic.com/research/anthropic-economic-index-september-2025-report</link>
      <description>Latest from Anthropic: Anthropic Economic Index report: Uneven geographic and enterprise AI adoption (Джерело: News)</description>
      <guid isPermaLink="false">https://www.anthropic.com/research/anthropic-economic-index-september-2025-report</guid>
      <category>Research</category>
      <pubDate>Wed, 19 Nov 2025 08:30:57 +0000</pubDate>
    </item>
    <item>
      <title>[Новини] Follow AnthropicAnthropic on XLinkedIn</title>
      <link>https://x.com/AnthropicAI</link>
      <description>Latest from Anthropic: Follow AnthropicAnthropic on XLinkedIn (Джерело: News)</description>
      <guid isPermaLink="false">https://x.com/AnthropicAI</guid>
      <category>News</category>
      <pubDate>Wed, 19 Nov 2025 08:30:57 +0000</pubDate>
    </item>
    <item>
      <title>[Новини] Media assetsDownload press kit</title>
      <link>https://anthropic.com/press-kit</link>
      <description>Latest from Anthropic: Media assetsDownload press kit (Джерело: News)</description>
      <guid isPermaLink="false">https://anthropic.com/press-kit</guid>
      <category>News</category>
      <pubDate>Wed, 19 Nov 2025 08:30:57 +0000</pubDate>
    </item>
    <item>
      <title>[Новини] Claude now available in Microsoft Foundry and Microsoft 365 Copilot</title>
      <link>https://www.anthropic.com/news/claude-in-microsoft-foundry</link>
      <description>ProductClaude now available in Microsoft Foundry and Microsoft 365 Copilot... (Джерело: News)</description>
      <guid isPermaLink="false">https://www.anthropic.com/news/claude-in-microsoft-foundry</guid>
      <category>Product</category>
      <pubDate>Wed, 19 Nov 2025 08:30:57 +0000</pubDate>
    </item>
    <item>
      <title>[Новини] Microsoft, NVIDIA, and Anthropic announce strategic partnerships</title>
      <link>https://www.anthropic.com/news/microsoft-nvidia-anthropic-announce-strategic-partnerships</link>
      <description>AnnouncementsMicrosoft, NVIDIA, and Anthropic announce strategic partnerships... (Джерело: News)</description>
      <guid isPermaLink="false">https://www.anthropic.com/news/microsoft-nvidia-anthropic-announce-strategic-partnerships</guid>
      <category>Announcements</category>
      <pubDate>Wed, 19 Nov 2025 08:30:57 +0000</pubDate>
    </item>
    <item>
      <title>[Новини] Anthropic partners with Rwandan Government and ALX to bring AI education to hundreds of thousands of learners across Africa</title>
      <link>https://www.anthropic.com/news/rwandan-government-partnership-ai-education</link>
      <description>AnnouncementsAnthropic partners with Rwandan Government and ALX to bring AI education to hundreds of thousands of learners across Africa... (Джерело: News)</description>
      <guid isPermaLink="false">https://www.anthropic.com/news/rwandan-government-partnership-ai-education</guid>
      <category>Announcements</category>
      <pubDate>Wed, 19 Nov 2025 08:30:57 +0000</pubDate>
    </item>
    <item>
      <title>[Новини] Disrupting the first reported AI-orchestrated cyber espionage campaign</title>
      <link>https://www.anthropic.com/news/disrupting-AI-espionage</link>
      <description>PolicyDisrupting the first reported AI-orchestrated cyber espionage campaign... (Джерело: News)</description>
      <guid isPermaLink="false">https://www.anthropic.com/news/disrupting-AI-espionage</guid>
      <category>Policy</category>
      <pubDate>Wed, 19 Nov 2025 08:30:57 +0000</pubDate>
    </item>
    <item>
      <title>[Новини] The state of Maryland partners with Anthropic to better serve residents</title>
      <link>https://www.anthropic.com/news/maryland-partnership</link>
      <description>AnnouncementsThe state of Maryland partners with Anthropic to better serve residents... (Джерело: News)</description>
      <guid isPermaLink="false">https://www.anthropic.com/news/maryland-partnership</guid>
      <category>Announcements</category>
      <pubDate>Wed, 19 Nov 2025 08:30:57 +0000</pubDate>
    </item>
    <item>
      <title>[Новини] Measuring political bias in Claude</title>
      <link>https://www.anthropic.com/news/political-even-handedness</link>
      <description>ProductMeasuring political bias in Claude... (Джерело: News)</description>
      <guid isPermaLink="false">https://www.anthropic.com/news/political-even-handedness</guid>
      <category>Product</category>
      <pubDate>Wed, 19 Nov 2025 08:30:57 +0000</pubDate>
    </item>
    <item>
      <title>[Новини] Anthropic invests $50 billion in American AI infrastructure</title>
      <link>https://www.anthropic.com/news/anthropic-invests-50-billion-in-american-ai-infrastructure</link>
      <description>AnnouncementsAnthropic invests $50 billion in American AI infrastructure... (Джерело: News)</description>
      <guid isPermaLink="false">https://www.anthropic.com/news/anthropic-invests-50-billion-in-american-ai-infrastructure</guid>
      <category>Announcements</category>
      <pubDate>Wed, 19 Nov 2025 08:30:57 +0000</pubDate>
    </item>
    <item>
      <title>[Новини] New offices in Paris and Munich expand Anthropic’s European presence</title>
      <link>https://www.anthropic.com/news/new-offices-in-paris-and-munich-expand-european-presence</link>
      <description>AnnouncementsNew offices in Paris and Munich expand Anthropic’s European presence... (Джерело: News)</description>
      <guid isPermaLink="false">https://www.anthropic.com/news/new-offices-in-paris-and-munich-expand-european-presence</guid>
      <category>Announcements</category>
      <pubDate>Wed, 19 Nov 2025 08:30:57 +0000</pubDate>
    </item>
    <item>
      <title>[Новини] Launching the Anthropic Economic Futures Programme in the UK and Europe</title>
      <link>https://www.anthropic.com/news/economic-futures-uk-europe</link>
      <description>Economic ResearchLaunching the Anthropic Economic Futures Programme in the UK and Europe... (Джерело: News)</description>
      <guid isPermaLink="false">https://www.anthropic.com/news/economic-futures-uk-europe</guid>
      <category>Research</category>
      <pubDate>Wed, 19 Nov 2025 08:30:57 +0000</pubDate>
    </item>
  </channel>
</rss>
